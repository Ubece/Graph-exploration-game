{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Provisional Grade Calculator\n",
    "\n",
    "The `tester.ipynb` Jupyter Notebook is provided to assist you with both the initialization of the system and the execution of operations using the `GameController` class. This notebook includes a series of cells corresponding to each operation you need to test within your implementation. To evaluate a specific operation, simply run the cell associated with that operation.\n",
    "\n",
    "### Important Instructions:\n",
    "- **Running Evaluation Cells**: Each cell corresponding to a specific operation will evaluate the correctness of your implementation for that operation and contribute to your provisional grade. **Running the same cell multiple times will update the provisional grade each time, which may be misleading.** \n",
    "- **Understanding Your Grade**: The grade calculated by this notebook is provisional and is based on the operations tested within this notebook. It is unlikely to cover all possible scenarios or test cases. **The final assessment may differ, and thus, the grade obtained through this notebook should be viewed as indicative and not final.**\n",
    "- **Developing Additional Test Cases**: You are encouraged to write your own test cases in addition to those provided. This will help ensure your implementation can handle a broader range of scenarios, potentially identifying edge cases not covered by this tester.\n",
    "\n",
    "### Grading Criteria:\n",
    "- **Graph Exploration via DFS:** 25 Points\n",
    "- **Rally Allies via BFS:** 25 Points\n",
    "- **Treasure Hunt via Dijkstra:** 40 Points\n",
    "- **README.MD File**: Provide a README.MD file, documenting your operations, usage instructions, and suggestions for improving the hash functions. This file is worth 10 Points.\n",
    "\n",
    "The overall provisional grade proposed by the tester will be out of 90, which is to be completed to 100 with the grade obtained from the README.MD file.\n",
    "\n",
    "Remember, this is a tool to assist you in your development process and should be used as one part of your overall testing and validation strategy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize the System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Worth of each operation\n",
    "dfs_total_worth = 25\n",
    "bfs_total_worth = 25\n",
    "dijkstra_total_worth = 40\n",
    "\n",
    "# grade proposed\n",
    "provisional_grade = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize GameController"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from GameController import GameController\n",
    "\n",
    "input_file_path = \"gameWorld.dat\"\n",
    "controller = GameController(input_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Exploration (DFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_dfs = ['1', '2', '3', '5', '4', '6', '7', '8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of tests to be run\n",
    "number_of_dfs_tests = 1 \n",
    "dfs_points_per_test = dfs_total_worth / number_of_dfs_tests\n",
    "# test if dfs result matches expected result\n",
    "if controller.explore() == expected_dfs:\n",
    "    provisional_grade += dfs_points_per_test\n",
    "    print(\"DFS test passed\")\n",
    "print (\"DFS test grade: \", provisional_grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Rally Allies (BFS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_allies =['2', '4', '8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of tests to be run\n",
    "number_of_bfs_tests = 1 \n",
    "bfs_points_per_test = dfs_total_worth / number_of_dfs_tests\n",
    "# test if dfs result matches expected result\n",
    "if controller.rally_allies() == expected_allies:\n",
    "    provisional_grade += bfs_points_per_test\n",
    "    print(\"BFS test passed\")\n",
    "print (\"BFS test grade: \", provisional_grade)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Treasure Hunt (Dijkstra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_treasures = [(['1', '2', '3'], 5),\n",
    "                      (['1', '4', '5'], 3),\n",
    "                      (['1', '4', '5', '6'], 6),\n",
    "                      (['1', '7'], 5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the number of tests to be run\n",
    "number_of_dijkstra_tests = 1 \n",
    "dijkstra_points_per_test = dijkstra_total_worth / number_of_dfs_tests\n",
    "# test if dfs result matches expected result\n",
    "if controller.treasure_hunt() == expected_treasures:\n",
    "    provisional_grade += dijkstra_points_per_test\n",
    "    print(\"BFS test passed\")\n",
    "print (\"Dijkstra test grade: \", provisional_grade)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
